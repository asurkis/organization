= Билеты по алгоритмам
:language: Russian
:toc:
:source-highlighter: rouge
:source-language: julia
:stem: asciimath

== Теормин
Алгоритм.
Память и время как ресурсы.
Вычисление чисел Фибоначчи:
экспоненциальный рекурсивный алгоритм,
полиномиальный алгоритм.
O-символика как инструмент оценки ресурсов,
различные асимптотики (логарифм, полином, экспонента).
Все алгоритмы курса: оценки сложности и решаемые ими задачи.

=== Числа Фибоначчи

.Экспоненциальный алгоритм:
[source]
----
function fib(n)
    if n < 2
        n
    else
        fib(n - 1) + fib(n - 2)
    end
end
----

.Полиномиальный (линейный) алгоритм:
[source]
----
function fib(n)
   a = 0
   b = 1
   for i=1:n
       c = a + b
       a = b
       b = c
   end
   a
end
----

.Логарифмический алгоритм:
[source]
----
# Возведение матрицы в степень
using LinearAlgebra function fib(n)
   function helper(mat, pow)
       if pow <= 1
           mat
       else
           tmp = helper(mat, pow ÷ 2)
           tmp *= tmp
           if pow % 2 == 1
               tmp *= mat
           end
           tmp
       end
   end
   (helper([0 1; 1 1], n) * [0; 1])[1]
end
----

=== O-нотация

[stem]
++++
f in O(g) <=> exists C > 0, N | forall n >= N : f(n) < C * g(n)

f in Omega(g) <=> exists C > 0, N | forall n >= N : f(n) > C * g(n)

Theta(g(n)) = O(g) nn Omega(g)

f in cc "o"(g) <=> forall C > 0 exists N | forall n >= N : f(n) < C * g(n)

f in omega(g) <=> forall C > 0 exists N | forall n >= N : f(n) > C * g(n)
++++

== 1. Элементарные структуры данных
Массивы переменного размера: аддитивная и мультипликативная схемы реаллокации.
Односвязный список, двусвязный список.
Абстрактные типы данных, интерфейс и реализация.
Стек, очередь, дек; моделирование на основе массива.
Моделирование очереди с помощью двух стеков.
Амортизационный анализ: метод учётных стоимостей операций и метод предоплаты.

=== Массивы переменного размера
* Доступ к любому элементу за stem:[O(1)]
* Вставка в конец
* Удаление с конца

==== Аддитивная схема
Раз в несколько добавлений происходит переаллокация.
Сложность: начинаем с пустого массива,
stem:[k] реаллокаций раз в stem:[m] элементов.
Тогда время работы --
[stem]
++++
mk + sum_(i=0)^(k-1) mi = \
= m sum_(i=1)^k i = \
= m (k (k + 1)) / 2 in \
in O(mk^2) = O(n^2)
++++
Амортизированная сложность -- stem:[O(n)] на одну вставку в конец.

==== Мультипликативная схема
Переаллокация умножает размер массива.
Амортизированная сложность: начинаем с пустого массива,
размер каждый раз умножается на stem:[q], добавляем stem:[floor(q^k)] элементов.
Тогда время работы --
[stem]
++++
floor(q^k) + sum_(i=0)^(k-1) floor(q^i) = \
= sum_(i=0)^k floor(q^i) <= \
<= sum_(i=0)^k q^i = \
= 1 + q * (1 - q^k) / (1 - q) = \
= (q^(k+1) - 1) / (q - 1) in \
in O(q^k) = O(n)
++++
Амортизированная сложность -- stem:[O(1)] на одну вставку в конец.

=== Списки
==== Односвязный
* Доступ к первому элементу за stem:[O(1)]
* Вставка в любую точку за stem:[O(1)]
* Удаление из любой точки за stem:[O(1)]

==== Двусвязный
* Односвязный список + указатель назад
* Соединение за stem:[O(1)]

=== Абстрактные типы данных
==== Интерфейс
* Список допустимых операций
* Инварианты

==== Реализация
* Конкретные алгоритмы

==== Стек
* Вставка в начало
* Удаление из начала

==== Очередь
* Вставка в конец
* Удаление из начала

==== Дек
* Стек + очередь

=== Дек на массиве
* Массив переменного размера
* Номер начала
* Количество элементов
* Вставка -- если хватает места, то циклическое смещение итератора (при вставке в начало)
  и установка значения, затем смена количества элементов.
  Если места не хватает -- переаллокация массива.
* Удаление -- выбор значения либо по итератору, либо по циклическому смещению,
  затем смена количества элементов.
* Дек является и списком, и очередью

[source]
----
mutable struct Deque{T}
    arr :: Vector{T}
    first :: Int64
    size :: Int64
    Deque{T}() where T = new(Vector{T}(undef, 1), 1, 0)
end

function ensure_capacity!(deque :: Deque{T}, capacity :: Int64) where T
    length(deque.arr) < capacity || return
    new_arr = Vector{T}(undef, 2 * length(deque.arr))
    for i=1:deque.size
        new_arr[i] = deque.arr[(deque.first + i - 2) % length(deque.arr) + 1]
    end
    deque.arr = new_arr
    deque.first = 1
end

function push_back!(deque :: Deque{T}, x :: T) where T
    ensure_capacity!(deque, deque.size + 1)
    deque.arr[(deque.first + deque.size - 1) % length(deque.arr) + 1] = x
    deque.size += 1
end

function push_front!(deque :: Deque{T}, x :: T) where T
    ensure_capacity!(deque, deque.size + 1)
    deque.first = (deque.first + length(deque.arr) - 2) % length(deque.arr) + 1
    deque.arr[deque.first] = x
    deque.size += 1
end

function pop_back!(deque :: Deque{T}) where T
    deque.size -= 1
    deque.arr[(deque.first + deque.size - 1) % length(deque.arr) + 1]
end

function pop_front!(deque :: Deque{T}) where T
    x = deque.arr[deque.first]
    deque.first = deque.first % length(deque.arr) + 1
    deque.size -= 1
    x
end
----

=== Очередь на двух стеках
[source]
----
mutable struct Queue{T}
    left :: Deque{T}
    right :: Deque{T}
    Queue{T}() where T = new(Deque{T}(), Deque{T}())
end

function queue_push!(q :: Queue{T}, x :: T) where T
    push_back!(q.right, x)
end

function queue_pop!(q :: Queue{T}) where T
    if q.left.size == 0
        while q.right.size != 0
            push_back!(q.left, pop_back!(q.right))
        end
    end
    pop_back!(q.left)
end
----

=== Амортизационный анализ
Средняя стоимость операции за большое количество действий.

Пример: стек с операцией stem:["multipop"(n)]
-- для удаления stem:[n] элементов за stem:[O(n)] сначала их нужно добавить,
чему предшествуют stem:[n] операций stem:["push"(x)] за stem:[O(1)].
Всего -- stem:[n + 1] операция, поэтому амортизированная стоимость
-- stem:[(2n) / (n + 1) = O(1)].

Например, двоичный счётчик, где изменение 1 бита -- stem:[O(1)].
Тогда stem:[i]-й бит изменится stem:[n * 2^{-i}] раз,
всего на stem:[n] действий -- stem:[<= 2n = O(n)] времени,
следовательно, на одно действие -- stem:[O(1)] времени в среднем.

==== Метод потенциалов
Заведём stem:[Phi] -- потенциал.
После выполнения stem:[i] действий потенциал -- stem:[Phi_i].
Обозначим _стоимость_ операции stem:[alpha_i = t_i + Phi_i - Phi_{i - 1}].
Тогда если
[stem]
++++
{{:
[forall i : alpha_i in O(f(n, m))],
[forall i : Phi_i in O(n * f(n, m))]
:}:}
++++
то средняя амортизационная стоимость stem:[t in O(f(n, m))].

Доказательство:
[stem]
++++
a = 1/n sum_(i=1)^n t_i = \
= 1/n sum_(i=1)^n (alpha_i - Phi_i + Phi_{i - 1}) = \
= 1/n (sum_(i=1)^n alpha_i - sum_(i=1)^n Phi_i + sum_(i=1)^n Phi_{i - 1}) = \
= 1/n (sum_(i=1)^n alpha_i - sum_(i=1)^n Phi_i + sum_(i=0)^(n-1) Phi_i) = \
= 1/n (sum_(i=1)^n alpha_i - Phi_N + Phi_0) = \
= 1/n (sum_(i=1)^n O(f(n, m)) - O(n * f(n, m)) + O(n * f(n, m))) = \
= O(f, n)
++++

Пример: стек с stem:["multipop"(n)]:
* Потенциал -- количество элементов в стеке stem:[n in O(n * 1)]
* stem:[alpha("push") = 1 + Delta Phi = 2 in O(1)]
* stem:[alpha("pop") = 1 + Delta Phi = 0 in O(1)]
* stem:[alpha("multipop"(n)) = n + Delta Phi = 0 in O(1)]
Следовательно, амортизированная стоимость операций -- stem:[t in O(1)].

==== Метод предоплаты
Заводим учётные стоимости stem:[alpha_i] так, что
stem:[sum_(i=1)^n alpha_i >= sum_(i=1)^n t_i].
Тогда stem:[forall i : alpha_i in O(f) => a in O(f)].

Пример: стек с stem:["multipop"(n)].
Для stem:["push"] будем использовать 2 монеты,
тогда учётную стоимость удалений можно принять равной 0,
используя оставшуюся "лишнюю" монету после вставки.
Тогда stem:[a in O(f)].

== 2. Разделяй и властвуй
Рекуррентные соотношения.
Метод «разделяй и властвуй».
Умножение n-битовых чисел:
простой рекурсивный алгоритм,
улучшенный рекурсивный алгоритм.
Рекуррентные соотношения: основная теорема.
Двоичный поиск.

=== Метод «разделяй и властвуй»
Разбиваем задачу на подзадачи кратно меньшего размера.

=== Умножение n-битовых чисел
==== Простой рекурсивный алгоритм
Пусть stem:[X = 2^n a + b; Y = 2^n c + d] -- нижние и верхние половины,
каждая половина -- размера stem:[n].
[stem]
++++
X * Y = 2^(2n) * a * c + 2^n * (a * d + b * c) + c * d
++++
Тогда
[stem]
++++
{{:
[ T(1) = 1 ],
[ T(2n) = 4 T(n) + 4n ]
:}:}

T(n) = 3n^2 - 2n = O(n^2)
++++

==== Улучшенный рекурсивный алгоритм
Трюк Гаусса:
[stem]
++++
(a + bi) (c + di) = ac - bd + (ad + bc) i \
(a + b) (c + d) = ac + bd + ad + bc \
ad + bc = (a + b) (c + d) - ac - bd \

X = 2^n a + b \
Y = 2^n c + d \
X * Y = 2^(2n) ac + 2^n (ad + bc) + bd = \
= 2^(2n) ac + 2^n ((a + b)(c + d) - ac - bd) + bd
++++
То есть количество умножений сокращается с 4 до 3.
Алгоритм Карацубы.

[stem]
++++
{{:
[ T(1) = 1 ],
[ T(2n) = 3 T(n) + 8n ]
:}:}

T(2^k) = sum_(i=0)^k 3^i * 8 * 2^(k - i) = \
= 8 * 2^k * sum_(i=0)^k 3^i * 2^(-i) = \
= 8 * 2^k * sum_(i=0)^k (3/2)^i = \
= 8 * 2^k * (1 - (3/2)^(k + 1)) / (1 - 3/2) = \
= 16 * 2^k * ((3/2)^(k + 1) - 1)

T(n) = 16n * ((3/2)^(log_2 n + 1) - 1) = \
= O(n * (3/2)^(log_2 n)) = O(3^(log_2 n))
++++

=== Рекуррентные соотношения: основная теорема (master theorem)
[stem]
++++
T(n) = a * T(ceil(n / b)) + O(n^d)

a, b in NN, b > 1, d >= 0

a > b^d => T(n) in O(n^(log_b a))

a < b^d => T(n) in O(n^d)

a = b^d => T(n) in O(n^d log n)
++++

=== Двоичный поиск
Заводим предикат stem:[P(i) | forall j > i : P(i) -> P(j)],
т.е. он становится верным в какой-то точке, и во всех последующих он тоже верен.
Тогда можно завести stem:[l] и stem:[r], и, поддерживая инвариант
stem:[not P(l) ^^ P(r)], найти точку смены значения за stem:[O(log(r - l))]:

. Находим stem:[m = (l + r) / 2]
. Если stem:[P(m)], то stem:[r := m]
. Иначе stem:[l := m]
. Повторяем, пока stem:[m notin {l, r}] (для целых чисел это будет stem:[l + 1 = r]) или до сходимости.

Теперь в stem:[l] -- самая правая точка, для которой предикат ещё не выполняется,
а stem:[r] -- самая левая, для которой выполняется.
Например, если stem:[P(i) = a\[i\] >= x], то stem:[a\[l\] < x; a\[r\] >= x].

== 3. Сортировка: квадратичные и сортировка слиянием
Квадратичные сортировки. Сортировка слиянием: с рекурсией и без.
Нижняя оценка stem:[Omega(n log n)] для сортировки сравнениями.

=== Квадратичные сортировки
* Пузырьком (элемент переставляется со следующим)
* Выбором
* Вставками -- хорошая константа

=== Сортировка слиянием
==== Рекурсивная
. Рекурсивно отсортировать левую и правую половины
. Слить их за stem:[O(n_i)]

* На одном "уровне слияния" -- ровно stem:[Theta(n)] действий
* Высота дерева -- stem:[Theta(log n)]
* Итоговая асимптотика -- stem:[Theta(n log n)]

==== Нерекурсивная
. Начинаем с подмассивов длины 1
. Переходим по длине stem:[n -> 2n] со слиянием stem:[2n - 1]-го и stem:[2n]-го соседей
. Повторяем в цикле, пока не будет единственный подмассив

=== Нижняя оценка для сортировки сравнениями
* Существует stem:[n!] возможных перестановок, и нужно выбрать одну из них всех
* Представим все возможные перестановки как листья дерева, в узлах которого -- сравнения
* Это будет stem:[k]-арное дерево, следовательно, его высота будет не меньше stem:[Omega (log_k (n!))]

[stem]
++++
Omega(log_k (n!)) = Omega(log (n!))

log (n!) = log (prod_(i=1)^n i) = \
= sum_(i=1)^n log i >= \
>= sum_(i=ceil(n/2))^n log ceil(n/2) = \
= ceil(n/2) * log ceil(n/2) >= \
>= n/2 * log (n/2) = \
= n/2 * (log n - log 2) >= \
>= [ n >= 4 ] >= n/4 * (log n - 1/2 log n) = \
= n/4 * log n = Omega(n log n)
++++

То есть любая сортировка сравнениями работает за stem:[Omega(n log n)],
что и требовалось доказать.

== 4. Сортировка кучей
Куча, построение кучи за линейное время.
Очередь с приоритетами на основе кучи.
Сортировка с помощью кучи, частичная сортировка.
Операции с d-ичной кучей.

=== Куча
* Дерево на массиве, индексация с 1
* Родитель stem:[k] имеет индекс stem:[floor((k - 1) / 2)]
* Инвариант: ключ в потомке не больше ключа в родителе (куча по максимуму)
* Просеивание вниз и вверх
** При просеивании вниз наверх вытягивается наибольший (в куче по максимуму) потомок
* Удаление -- через перестановку вершины с последним элементом и просеивание вниз новой вершины

=== Построение кучи за линейное время
* Начинаем с листьев, идём к корню
* Соединяем уже построенные кучи + элемент в кучу
** То есть для элемента stem:[i] сначала делаем кучи с корнями
   в stem:[2i] и stem:[2i + 1], а затем делаем
   SiftDown на stem:[i]
* Можно идти с конца до начала массива, но из-за кеширования лучше использовать обход в глубину

Время работы: stem:[T(2^(k + 1) - 1) = 2T(2^k - 1) + O(k)].
Можно заметить, что время работы не убывает от количества элементов.
Тогда stem:[T(n) <= 2 T ceil(n / 2) + O(log n) <= 2 T ceil(n / 2) + O(sqrt n)]

По основной теореме stem:[2 > sqrt 2 => T(n) in O(n^(log_2 2)) = O(n)]

=== Очередь с приоритетами на основе кучи
- См. операции с кучей

=== Сортировка с помощью кучи
. Построить кучу из всех элементов массива, stem:[O(n)]
. Извлекать по одному элементу из кучи и ставить на место, stem:[O(n * log n)]

Время работы -- stem:[O(n * log n)]

=== Частичная сортировка
* Нужно достать только первые stem:[k] порядковых статистик из stem:[n] элементов
* Строим кучу на первых stem:[k] элементах неотсортированного массива, stem:[O(k)]
* Проходим по всем оставшимся stem:[n - k] элементам массива, на каждом шаге:
*. Добавляем очередной элемент массива, stem:[O(log k)]
*. Удаляем вершину кучи (наибольший элемент), stem:[O(log k)]
* В конце остались stem:[k] наименьших элементов массива, и все в куче
* Сортируем их кучей, получаем stem:[k] упорядоченных наименьших элементов массива, stem:[O(k log k)]

Итого время работы: stem:[O(k) + (n - k) O(log k) + O(k log k) = O(k + n log k) = O(n log k)]

=== Операции с d-ичной кучей
* Посмотреть на вершину (максимум), stem:[O(1)]
* Извлечь вершину (максимум), stem:[O(log n)]
* Добавить элемент, stem:[O(log n)]
* Заменить ключ -- если поддерживать словарь,
  для чего достаточно сбалансированного дерева,
  то можно узнать положение ключа в куче за stem:[O(log n)].
  Если известно положение ключа, то можно этот ключ заменить или извлечь
  путём просеивания сначала вверх, затем вниз за stem:[O(log n)].
* Слияние куч (?)

== 5. Быстрая сортировка

Анализ среднего времени работы,
анализ глубины рекурсии,
элиминация хвостовой рекурсии,
IntroSort,
массивы с малым количеством различных элементов,
QuickSort3.

=== Анализ среднего времени работы
Предположим, что все ключи различны.
Первым pivot'ом массив разделяется на подмассивы длины stem:[i] и stem:[n - i - 1].
stem:[i] равновероятен от 0 до stem:[n - 1].
[stem]
++++
T(n) = O(n) + 1 / (n - 1) sum_(i=0)^(n - 1) (T(i) + T(n - i - 1)) = \
= O(n) + 2 / (n - 1) sum_(i=2)^(n - 1) T(i)
++++

Пусть stem:[alpha > 0] -- константа в stem:[O(n)].
Докажем, что stem:[exists beta > 0 | forall n >= 2 : T(n) <= beta n log n].
Очевидно, что для stem:[n = 2] утверждение выполняется.
Пусть оно выполнено stem:[forall N < n].
Рассмотрим stem:[n].
[stem]
++++
"Пусть" n' = floor(n / 2)

T(n) = O(n) + 2 / (n - 1) sum_(i=2)^(n - 1) T(i) <= \
<= alpha n + (2 beta) / (n - 1) sum_(i=2)^(n - 1) (i log i) = \
= alpha n + (2 beta) / (n - 1) (sum_(i=2)^n' i log i + sum_(i=n' + 1)^(n - 1) i log i) <= \
<= alpha n + (2 beta) / (n - 1) (log n/2 * sum_(i=2)^n' i + log n * sum_(i=n' + 1)^(n - 1) i) = \
= alpha n + (2 beta) / (n - 1) (log n * sum_(i=2)^(n - 1) i - log 2 * sum_(i=2)^n' i) <= \
<= alpha n + (2 beta) / (n - 1) (log n * ((n + 1)(n - 2))/2 - log 2 * ((n' + 2)(n' - 1))/2) <= \
<= alpha n + beta (log n * (n + 1) - log 2 * ((n' + 2)(n' - 1)) / (n - 1)) <= \
<= alpha n + beta (log n * (n + 1) - log 2 * (((n-1)/2 + 2)((n-1)/2 - 1)) / (n - 1)) <= \
<= alpha n + beta (log n * (n + 1) - log 2 * ((n + 3)(n - 3)) / 4(n - 1)) <= \
<= alpha n + beta (log n * (n + 1) - log 2 * (n - 3) / 4) = \
= beta n log n + (alpha n + beta log n - beta (n - 3) / 4)
++++

При достаточно большом stem:[beta] слагаемое
stem:[alpha n + beta log n - beta (n - 3) / 4] будет отрицательным начиная с некоторого stem:[n].
Тогда stem:[exists beta > 0, N in NN | forall n >= N : T(n) <= beta n log n].
Очевидно, можно также подобрать stem:[beta] ещё больше, чтобы утверждение было верным
stem:[forall n >= 2].

=== Анализ глубины рекурсии
stem:[D(n)] -- математическое ожидание глубины рекурсии.
[stem]
++++
D(n) = 1 + 1 / (n - 1) sum_(i=0)^(n - 1) max(D(i), D(n - i - 1))
++++
Пусть stem:[exists beta : D(n) < beta * log n]
верно stem:[forall N < n].
Рассмотрим stem:[n]:
[stem]
++++
D(n)
= 1 + 1 / (n - 1) sum_(i=0)^(n - 1) max(beta * log i, beta * log(n - i - 1)) = \
= 1 + (2 beta) / (n - 1) sum_(i=ceil((n - 1)/2))^(n - 1) log i) <= \
<= 1 + beta / (n - 1) * (n - 1) * log n = \
= 1 + beta * log n in O(log n) \
++++
Аналогично, stem:[D(n) in O(log n)].

=== Элиминация хвостовой рекурсии
Второй рекурсивный вызов -- хвостовой.
Его можно преобразовать в цикл.
Поскольку рекурсивные вызовы независимы,
можно выполнить сначала тот, который будет на более коротком отрезке,
а затем сделать более длинный -- хвостовым.

=== IntroSort
Разделителем на каждом шаге выбирается медиана из трёх элементов массива
(например, левой и правой границ и середины массива).
При превышении глубины рекурсии stem:[c * log_2 n]
переходим от быстрой сортировки к сортировке с гарантированным stem:[O(n log n)],
например, сортировке кучей.

Преимущества:
* Гарантированно stem:[O(n log n)] по сравнению с обычной быстрой сортировкой, где в худшем случае stem:[O(n^2)]
* Небольшая константа, как и у быстрой сортировки
* Может тратить меньше памяти, чем сортировки с гарантированным stem:[O(n log n)]

=== Массивы с малым количеством различных элементов, QuickSort3
Отдельно выносим группу элементов, равных "поворотному",
тогда получается 3 отрезка с элементами
строго меньше, строго равными, и строго большими поворотного.
Очевидно, равные сортировать уже не нужно, и этот отрезок не пустой.

== 6. Линейные сортировки и порядковые статистики

Сортировка подсчётом, стабильность. Цифровая сортировка. Bucket sort для
равномерно распределённых вещественных чисел. Порядковые статистики,
нахождение за линейное в среднем время. Медиана медиан.

== 7. Динамическое программирование 1

Общие принципы динамического программирования. Кратчайшие пути в
ациклических ориентированных графах. Наибольшая возрастающая
подпоследовательность: подзадачи, порядок на подзадачах, граф подзадач,
сравнение с рекурсивным алгоритмом; нахождение не только длины, но и
самой подпоследовательности. Дискретная задача о рюкзаке.

== 8. Динамическое программирование 2

Умножение матриц. Независимые множества максимального веса в деревьях.
Редакционное расстояние: граф на подзадачах, нахождение кратчайшего пути
в данном графе; вычисление редакционного расстояния с использованием
линейной памяти (алгоритм Хиршберга).

== 9. Жадные алгоритмы 1

Покрытие точек единичными отрезками. Непрерывный рюкзак. Задача о выборе
заявок. Максимальные независимые множества в деревьях. Код Хаффмана.

== 10. Жадные алгоритмы 2

Минимальное покрывающее дерево: свойство разреза, жадная стратегия,
алгоритм Прима, алгоритм Краскала.

== 11. Система непересекающихся множеств

Представление множеств с помощью деревьев, эвристики: ранги и сжатие
путей, верхняя оценка stem:[O(m log^** n)] на время работы m операций.
Анализ учётных стоимостей операций: метод ростовщика.

== 12. Декомпозиция графов 1

Графы и способы их представления: матрица смежности, списки смежности,
матрица инцидентности. Поиск в глубину. Графы и способы их
представления, способы использования графов. Поиск в глубину в
неориентированных графах, выделение компонент связности, нахождение
циклов. Поиск в глубину в ориентированных графах: поиск цикла.

== 13. Декомпозиция графов 2

Поиск в глубину в ориентированных графах: топологическая сортировка
вершин, выделение компонент сильной связности в орграфах.

== 14. Кратчайшие пути в графах

Нахождение кратчайших путей из одной вершины в невзвешенных графах,
поиск в ширину. Нахождение кратчайших путей из одной вершины в графах с
положительными весами, алгоритм Дейкстры, оценка времени работы при
различных реализациях очереди с приоритетами (массивом, двоичной кучей,
d-ичной кучей).

== 15. Кратчайшие пути в графах с отрицательными рёбрами

Алгоритм Беллмана-Форда, проверка наличия цикла отрицательного веса.
Кратчайшие пути в ациклических ориентированных графах. Кратчайшие пути
между всеми парами вершин: алгоритм Флойда-Уоршелла.

== Примечания

Билет состоит из двух вопросов. При подготовке билетов пользоваться
любыми источниками запрещается. Билеты рассказываются устно. Кроме
материала билета нужно уметь отвечать и на вопросы по другим билетам.
После ответа выдаётся задача. Перед получением билета студенту
предлагается написать тест. Оценка за тест -- это максимальная оценка,
которую студент может получить за экзамен.
